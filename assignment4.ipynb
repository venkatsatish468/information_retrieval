{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\satish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\satish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(text):\n",
    "    return \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "def createTokens(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def removeNumbers(oldList):\n",
    "    file_remove_num = []\n",
    "    for word in oldList:\n",
    "        new_word = re.sub(r'\\d+','',word)\n",
    "        if new_word != '':\n",
    "            file_remove_num.append(new_word)\n",
    "    return file_remove_num\n",
    "\n",
    "def removeStopWords(numList):\n",
    "    stop_words = stopwords.words('english')\n",
    "    file_remove_stop_words = [word for word in numList if word not in stop_words]\n",
    "    return file_remove_stop_words\n",
    "\n",
    "def stemming(stopList):\n",
    "    porter = PorterStemmer()\n",
    "    file_stemmed = [porter.stem(word) for word in stopList]\n",
    "    return file_stemmed\n",
    "\n",
    "def preprocessData(String):\n",
    "    String = String.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    queryRemovePun=removePunctuation(String)\n",
    "    tokens=createTokens(queryRemovePun)\n",
    "    removeNum=removeNumbers(tokens)\n",
    "    RemoveStopWords=removeStopWords(removeNum)\n",
    "    Stemming=stemming(RemoveStopWords)\n",
    "    return Stemming\n",
    "\n",
    "def createInvertedIndex(processedData,vocabulary):\n",
    "    invertedIndex={}\n",
    "    for word in vocabulary:\n",
    "        invertedIndex[word]={}\n",
    "        for document,tokens in processedData.items():\n",
    "            invertedIndex[word][document]=tokens.count(word)\n",
    "    return invertedIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T1.txt\",\"r\")\n",
    "f2=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T2.txt\",\"r\")\n",
    "f3=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T3.txt\",\"r\")\n",
    "f4=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T4.txt\",\"r\")\n",
    "f5=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T5.txt\",\"r\")\n",
    "f6=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T6.txt\",\"r\")\n",
    "f7=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T7.txt\",\"r\")\n",
    "f8=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T8.txt\",\"r\")\n",
    "f9=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T9.txt\",\"r\")\n",
    "f10=open(\"C:/Users/satish/Documents/ir_assignment/textDocuments/T10.txt\",\"r\")\n",
    "f1Text=f1.read().lower()\n",
    "f2Text=f2.read().lower()\n",
    "f3Text=f3.read().lower()\n",
    "f4Text=f4.read().lower()\n",
    "f5Text=f5.read().lower()\n",
    "f6Text=f6.read().lower()\n",
    "f7Text=f7.read().lower()\n",
    "f8Text=f8.read().lower()\n",
    "f9Text=f9.read().lower()\n",
    "f10Text=f10.read().lower()\n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()\n",
    "f4.close()\n",
    "f5.close()\n",
    "f6.close()\n",
    "f7.close()\n",
    "f8.close()\n",
    "f9.close()\n",
    "f10.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1Stemming=preprocessData(f1Text)\n",
    "f2Stemming=preprocessData(f2Text)\n",
    "f3Stemming=preprocessData(f3Text)\n",
    "f4Stemming=preprocessData(f4Text)\n",
    "f5Stemming=preprocessData(f5Text)\n",
    "f6Stemming=preprocessData(f6Text)\n",
    "f7Stemming=preprocessData(f7Text)\n",
    "f8Stemming=preprocessData(f8Text)\n",
    "f9Stemming=preprocessData(f9Text)\n",
    "f10Stemming=preprocessData(f10Text)\n",
    "fileMergedStemming=f1Stemming+f2Stemming+f3Stemming+f4Stemming+f5Stemming+f5Stemming+f7Stemming+f8Stemming+f9Stemming+f10Stemming\n",
    "vocabulary=list(set(fileMergedStemming))\n",
    "vocabulary=sorted(vocabulary)\n",
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDictionary={\"T1.txt\":f1Stemming,\"T2.txt\":f2Stemming,\"T3.txt\":f3Stemming,\"T4.txt\":f4Stemming,\"T5.txt\":f5Stemming,\n",
    "                    \"T6.txt\":f6Stemming,\"T7.txt\":f7Stemming,\"T8.txt\":f8Stemming,\"T9.txt\":f9Stemming,\"T10.txt\":f10Stemming}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedIndex=createInvertedIndex(processedDictionary,vocabulary)\n",
    "# invertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1.txt</th>\n",
       "      <th>T2.txt</th>\n",
       "      <th>T3.txt</th>\n",
       "      <th>T4.txt</th>\n",
       "      <th>T5.txt</th>\n",
       "      <th>T6.txt</th>\n",
       "      <th>T7.txt</th>\n",
       "      <th>T8.txt</th>\n",
       "      <th>T9.txt</th>\n",
       "      <th>T10.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrevi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberdeen</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          T1.txt  T2.txt  T3.txt  T4.txt  T5.txt  T6.txt  T7.txt  T8.txt  \\\n",
       "abandon        0       0       0       0       0       0       0       0   \n",
       "abbrevi        0       0       0       0       0       0       1       0   \n",
       "abdomen        0       0       0       0       0       0       1       0   \n",
       "abdomin        0       0       0       0       0       0       1       0   \n",
       "aberdeen       1       0       0       0       0       0       0       0   \n",
       "\n",
       "          T9.txt  T10.txt  \n",
       "abandon        1        2  \n",
       "abbrevi        0        0  \n",
       "abdomen        0        0  \n",
       "abdomin        0        0  \n",
       "aberdeen       0        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invertedIndexDf = pd.DataFrame(invertedIndex).T\n",
    "invertedIndexDf.head(5)\n",
    "df=invertedIndexDf\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic model:\n",
    "Probability(p)=sum((N-N(w)+0.5)/(N(w)+0.5))<br>\n",
    "N = Total number of Documents<br>\n",
    "N(w) = Number of documents in which the word has occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandon       2\n",
      "abbrevi       1\n",
      "abdomen       1\n",
      "abdomin       1\n",
      "aberdeen      1\n",
      "             ..\n",
      "zoologist     1\n",
      "zoophyt       2\n",
      "§            10\n",
      "°             3\n",
      "æon           1\n",
      "Length: 4101, dtype: int64\n",
      " \n",
      "abandon      3.400000\n",
      "abbrevi      6.333333\n",
      "abdomen      6.333333\n",
      "abdomin      6.333333\n",
      "aberdeen     6.333333\n",
      "               ...   \n",
      "zoologist    6.333333\n",
      "zoophyt      3.400000\n",
      "§            0.047619\n",
      "°            2.142857\n",
      "æon          6.333333\n",
      "Length: 4101, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numberOfDocuments = 10\n",
    "wordOccurance = invertedIndexDf.astype(bool).sum(axis=1)\n",
    "probability = (numberOfDocuments-wordOccurance+0.5)/(wordOccurance+0.5)\n",
    "print(wordOccurance)\n",
    "print(\" \")\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the search query : evolution\n",
      "{'evolut'}\n"
     ]
    }
   ],
   "source": [
    "query = input(\"enter the search query : \")\n",
    "queryPreProcess = set(preprocessData(query))\n",
    "print(queryPreProcess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ranking': {'T1.txt': 0.29411764705882354, 'T2.txt': 1.0, 'T3.txt': 1.0, 'T4.txt': 0.29411764705882354, 'T5.txt': 0.29411764705882354, 'T6.txt': 0.29411764705882354, 'T7.txt': 0.29411764705882354, 'T8.txt': 0.29411764705882354, 'T9.txt': 0.29411764705882354, 'T10.txt': 0.29411764705882354}}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T2.txt</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3.txt</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T7.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T8.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9.txt</th>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ranking\n",
       "T2.txt   1.000000\n",
       "T3.txt   1.000000\n",
       "T1.txt   0.294118\n",
       "T10.txt  0.294118\n",
       "T4.txt   0.294118\n",
       "T5.txt   0.294118\n",
       "T6.txt   0.294118\n",
       "T7.txt   0.294118\n",
       "T8.txt   0.294118\n",
       "T9.txt   0.294118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = {}\n",
    "rank[\"Ranking\"]={}\n",
    "for document in invertedIndexDf:\n",
    "    common = (invertedIndexDf[invertedIndexDf[document]>0].index).intersection(queryPreProcess)\n",
    "    rank[\"Ranking\"][document]=probability[common].product()\n",
    "print(rank)\n",
    "print(\" \")\n",
    "rankDF = pd.DataFrame(rank).sort_values(\"Ranking\",ascending=False)\n",
    "rankDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolut\n",
      "T1.txt     17\n",
      "T2.txt      0\n",
      "T3.txt      0\n",
      "T4.txt      5\n",
      "T5.txt      1\n",
      "T6.txt     37\n",
      "T7.txt     62\n",
      "T8.txt      2\n",
      "T9.txt      7\n",
      "T10.txt     2\n",
      "Name: evolut, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for word in queryPreProcess:\n",
    "    if word in invertedIndexDf.index:\n",
    "        print(word)\n",
    "        print(invertedIndexDf.loc[word])\n",
    "    else:\n",
    "        print(word,\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
